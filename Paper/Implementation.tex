\subsection*{Elitist Schema Overlays}
Obviously, there are many different methodologies that we could utilize to build effective genetic overlays. The central focus of this paper is the use of \emph{Elitist Schema Overlays}, and they are conceptually defined below.

\begin{eschema}
A genetic overlay that is built from the matching alleles of the elite sub-population.
\end{eschema}

To define this formally, let $P = \{p_1,p_2,\ldots,p_n\}$ be a set of $n$ individuals selected for recombination. Consider $T=\{t_1,t_2,\ldots,t_k\}$ as the set of the $k$ individuals with the highest fitness rankings in the population. From $P$, we will create a new individual $c$.  We will now construct the genetic overlay, named $s$, to be applied to $c$ from the genetic sequences in $T$. The notations $s(i), t(i), \text{ and } c(i)$ represent the value, or lack-thereof in the case of the schema, at position $i$.
 
 \begin{displaymath}
   s(i) = \left\{
     \begin{array}{lr}
       t_1(i) \text{~~~if~ } t_1(i) = t_2(1) = \ldots = t_k(i) \\
       \text{empty~} \text{if~ } \text{otherwise} 
     \end{array}
   \right.
\end{displaymath} 

Thus, our schema will only have specified values where every individual in $T$ has the same value at that same position. If our best performing individuals all have the same values at various alleles, this may hint that these assignments are correlated with success. Thus, it would be reasonable to search the neighborhood of this partial solution more thoroughly. Below is an example of the creation and application of an Elitist Schema Overlay:
\begin{figure}[h!]
\centering 
\begin{align*}
\text{Elite Individual 1} &: 0~1~0~0~1~0~1~1~0 			\\
\text{Elite Individual 2} &: 0~1~0~0~0~0~1~0~0 			\\
\text{Elite Individual 3} &: 1~1~0~1~1~0~1~1~0 			\\
\text{Resultant Genetic Overlay} &:   -1~0--0~1-0			\\
\text{Unmodified New Individual} &: 1~0~0~1~1~0~1~1~1	\\		
\text{Resultant Individual} &: 1~1~0~1~1~0~1~1~0
\end{align*}
\caption{Production and Application of an Elitist Schema Overlay}
\end{figure}

It should be noted that our $c$ can be created using any existing, or future, genetic operator. This was done intentionally to explore its behavior in several scenarios. This process allows us to search around those genes that are common among the fittest members in our population. 

Admittedly, the effects of this method will depend greatly upon our choice of $k$. For instance, the choice $k = 1$ will replace every individual that has a genetic overlay applied with the highest ranked member of the population. This is problematic, since it will instantly lead us to convergence. Likewise, a large value of $k$, will greatly reduce the probability that $t_1(i) = t_2(i) = \ldots = t_k(i)$ is true. This would lead us to checking a large number of alleles and, in the likeliest case, doing little to nothing with that information.

Now we will determine the probability of a single allele matching across $k$ parents. We will denote $\alpha_i$ to be this value, and $\beta_i$ to represent the size of the domain of the $i$th allele. Note that this assumes that each value for an allele has an equal probability of showing up in a selected genetic sequence at allele $i$. If this is not the case, then this gives us a lower bound for the values more likely to occur at this position, and an upper bound for the values less likely to occur at this position.

\[ \alpha = P(\text{\emph{k} parents matching \emph{i}th allele}) = \big(\frac{1}{\beta_i}\big)^{k-1} \]

With this, we can easily derive the probabilities of having at least one match, no matches, and a total match for a chromosome of length $n$ in terms of $\alpha$.

\begin{align*}
P( \text{No matches})&= (1 - \alpha)^n \\
P( \text{At least 1 match}) &=\sum\limits^{n}_{r=1} \binom{n}{r}*\alpha^{r}*(1-\alpha)^{n-r} \\
P( \text{All matches})&= \alpha^n
\end{align*}

Thus, our choice of $k$ should be made carefully, but there are a large number of possibilities that we could easily consider. A fixed and predetermined $k$ could be chosen, $k$ could be randomized for each generation, or $k$ could be set to the number of individuals above a certain fitness threshold; however, the successes of Memetic Algorithms inspired a different approach. If we create an inverse relationship between the generations elapsed and our choice of $k$ we get some interesting properties:

\begin{enumerate}

\item Narrowing Search - Since the initial $k$ values will be very large, it is unlikely that $t_1(i) = t_2(i) = \ldots = t_k(i)$, and so we will not disturb the initial natural diversity with the operator.  Likewise, as our $k$ drops our genetic overlay has a higher chance to be mostly specified, thus we will be searching the narrowing neighborhood of the best performing solutions discovered so far \cite{Neri11}.

\item Bounded Convergence - We can control how quickly $k$ decreases, and by this, how quickly our population will converge towards the best known solutions. When we set $k=1$ we will instantly converge the entire target population of this operator, and so the minimum convergence rate can now be set by the user.

\end{enumerate}

\subsection*{Fitness-Based Scanning}
Another operator that will be implemented and tested is fitness-based scanning as proposed by Eiben et al\cite{Eiben94}. The generalized form of scanning iterated through the empty genetic sequence of a child and determined its value based upon the values present in $n$ selected parents\cite{Eiben91}. Fitness-based scanning makes a roulette wheel selection to choose each allele. At each allele, the probability that a parent, from the population $S$, named $i$ with a fitness value of $f(i)$ will donate its allele to the child's genetic sequence with probability $P(i)$ as described below\cite{Eiben94}: 

\[ P(i) = \frac{f(i)}{\sum\limits_{i \in S} f(i)} \]

\noindent Thus, the expected number of alleles inherited from a parent $i$ is $E(i)$\cite{Eiben94}:

\[ E(i) = P(i) *(\text{ Chromosome length }) \]

\subsection*{Diagonal Crossover}
\emph{Diagonal crossover} was introduced by Eiben et al. to extend the concept of crossover into the realm of multi-parent genetic operators\cite{Eiben03}. A diagonal crossover of arity $n$ can be described easily. Take $n$ individuals from a population, select $n-1$ crossover points, and create $n$ children by selecting one segment from each piece of the genetic sequences given\cite{Eiben95}. The figure below depicts how this would work\cite{Eiben95}:
\begin{figure}[h!]
\centering
\begin{tabular}{ | c | c | c | c | c | }
\hline
$a_1$ & $a_2$ & $a_3$ & $a_4$ & $\text{ parent a }$ 	\\ \hline
$b_1$ & $b_2$ & $b_3$ & $b_4$ & $\text{ parent b }$ 	\\ \hline
$c_1$ & $c_2$ & $c_3$ & $c_4$ & $\text{ parent c }$ 	\\ \hline
$d_1$ & $d_2$ & $d_3$ & $d_4$ & $\text{ parent d }$ 	\\ \hline
\end{tabular}
$\rightarrow$
\begin{tabular}{ | c | c | c | c | c | }
\hline
$a_1$ & $d_2$ & $c_3$ & $b_4$ & $\text{ child a }$ 	\\ \hline
$b_1$ & $a_2$ & $d_3$ & $c_4$ & $\text{ child b }$ 	\\ \hline
$c_1$ & $b_2$ & $a_3$ & $d_4$ & $\text{ child c }$ 	\\ \hline
$d_1$ & $c_2$ & $b_3$ & $a_4$ & $\text{ child d }$ 	\\ \hline
\end{tabular}
\caption{Diagonal crossover applied to four parents}
\end{figure} 

The rationale behind expanding this operator was to increase the disruptiveness, and by extension the explorativity, of Genetic Algorithms\cite{Eiben97}. This meant that the population would have to have a large degree of similar genetic sequences before the search would narrow and converge\cite{Eiben95}. It should also be noted that in the special case of $n = 2$ is identical to traditional 1-point crossover\cite{Eiben95}.

\subsection*{Permutation Algorithm}
For most applications, these operators will function correctly unmodified; however, for permutation based problems that allow for only one instance of a given value, like the Traveling Salesman and N-Queens Problems, a slight change is necessary. For instance, the application of an overlay might leave identical values in multiple positions in the genetic sequence, which is not permitted in either of these problems. This has been illustrated below: 
\begin{figure}[h!]
\centering 
\begin{align*}
\text{Genetic Overlay} &:   -1~3--6~2-9				\\
\text{New Individual} &: 2~1~3~4~5~7~6~8~9			\\		
\text{Resultant Individual} &: 2~1~3~4~5~6~2~1~9
\end{align*}
\caption{The Permutation Problem with Genetic Overlays}
\end{figure}

As we can see, the resultant individual now contains two instances of both 2 and 9, and lacks both a 7 and an 8. To solve this problem, we have created an algorithm that will check and fix individuals if they do not meet the uniqueness condition while still preserving any genetic overlays for which the uniqueness condition holds. This algorithm iterates through a genetic sequence, and for any value that is not in the genetic overlay (if applicable) it will check if it has been used exactly once in the permutation. It this is true, then we advance. Otherwise, we replace it with the closest value not in the permutation. The fact that a genetic overlay cannot contain duplicates and the fact that we cannot increase the number of duplicates in the permutation lets us know that the end result of this algorithm will always be a permutation. 