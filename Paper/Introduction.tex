Optimization problems are some of the most difficult problems to solve exactly; however, checking how good a particular solution is usually involves a fairly inexpensive computation. Thus, a natural strategy for problems like this would be to generate a large, random pool of solutions and use information from a quality check to find better solutions. This is central to how Genetic Algorithms operate. We can encode solutions to these problems as genetic sequences and then replicate the process of natural evolution on them. The quality checks, performed by the \emph{fitness function}, let us score a solution's fitness, or quality. The \emph{selection} operator uses these scores to determine which solutions performed well and should be kept for additional processing and those that did poorly and need to be discarded. We then derive additional potential solutions from those that were kept, which is done by a \emph{recombination} operator. Finally, it is helpful to change small components in these new solutions to expand our search with a \emph{mutation} operator \cite{Deb99}.

This methodology lets us quickly generate approximate solutions to these problems. Genetic Algorithms are not guaranteed to find the optimum solution, but they are able to find good approximations very efficiently \cite{Russell10}. Much research has gone into improving these approximations by modifying the strategies and heuristics used, and this paper aims to do the same.

Historically, Genetic Algorithms have been modeled closely after observations from Biology. For example, both biological reproduction and recombination in traditional Genetic Algorithms always occur with either 1 or 2 parent(s) involved; however, this is only a restriction in Biology \cite{Eiben95}. For Genetic Algorithms, the number of parents used during recombination can easily be expanded beyond 2. Papers describing techniques for multi-parent recombination started appearing as early as 1966, but little was reported about their behavior early on \cite{Eiben03}. The strategies investigated showed promise, and they have since drawn more attention and research\cite{Eiben94}. 

Curiously, many of these new operators were extensions of traditional recombination operators modified only to accommodate for more parents. In this paper, we follow the trend of diverging from the restrictions of Biology by introducing a new genetic operator, the \emph{elitist schema overlay}, and the more general concept of a \emph{genetic overlay}. This operator attempts to amplify the benefits of both crossover and fitness-based scanning by attempting to identify and propagate the genes correlated with the most successful solutions that have been discovered \cite{Russell10}. 

In the next section, we will define the core terminology of Genetic Algorithms.   Section 3 covers traditional genetic operators and two of the most successful genetic operators from the literature, diagonal crossover, or diagonalization, and fitness-based scanning. In Section 4, definitions for both genetic overlays and elitist schema overlays are given. Additionally, we have also presented the case for why this methodology is successful and how it follows from Genetic Algorithms theory. In Section 5, we define the numerical optimization functions and NP-Hard problems that we will test against. The encoding formats and support functions used to compute these are also defined in that section. Section 6 details how our experiments were set up, and an analysis of the data from those experiments.