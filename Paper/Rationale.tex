The selection phase of Genetic Algorithms determines the probability of a given individual being chosen for recombination based upon fitness. This is necessary in order to preserve the genes that performed well. This was conceptually expanded upon with elitism, allowing the best performing individual to survive into the next generation. Elitist schema overlays engrain this concept within a genetic operator, and are a special instance of genetic overlays:

\begin{overlay}
Genetic Overlay - A genetic operator which modifies an individual's genetic sequence to match the specified alleles of a given schema, while leaving the unspecified alleles at their original values. 
\end{overlay}

\begin{figure}[h!]
\centering 
\begin{align*}
\text{Initial Individual} &: 0~1~0~0~1~0 		\\
\text{Genetic Overlay} &: 1-0~1-0				\\
\text{Resultant Individual} &: 1~1~0~1~1~0			
\end{align*}

\caption{Genetic overlay on a binary genetic sequence}
\label{GO-Fig}
\end{figure}

Figure-\ref{GO-Fig} has simple example of a binary genetic overlay where the unspecified alleles have been marked with a dash. The \emph{defining length} of a schema is the number of specified values, in this case $4$.

This operator allows us to quickly give a set of individuals very similar genetic sequence, thus allowing us to search the neighborhood of the provided schema. The choice and density of the schema that we use is very important. If our schema is very dense, i.e. it consists of mostly specified alleles, then the population will converge very quickly. Early convergence is problematic because it lessens the probability that the optimal solution has been found\cite{Deb99}. Likewise, a very sparse schema will spend excess computation cycles applying very few changes. Additionally, we want to ensure that our schema consists of alleles that yield high fitness values. Each of these factors must be carefully considered when developing a strategy for creating genetic overlays. 

\subsection*{Elitist Schema Overlays}
There are many reasonable methodologies that we could utilize to build effective genetic overlays. The central focus of this paper is the use of \emph{elitist schema overlays}, and they are conceptually defined below.

\begin{overlay}
Elitist Schema Overlay - A genetic overlay that is built from the matching alleles of the elite sub-population.
\end{overlay}

To define this formally, let $P = \{p_1,p_2,\ldots,p_n\}$ be a set of $n$ individuals selected for recombination. Consider $T=\{t_1,t_2,\ldots,t_k\}$ as the set of the $k$ individuals with the highest fitness rankings in the population. From $P$, we will create a new individual $c$.  We will now construct the genetic overlay, named $s$, to be applied to $c$ from the genetic sequences in $T$. The notations $s[i], t[i], \text{ and } c[i]$ represent the value, or lack-thereof in the case of the schema, at position $i$. 
 
 \begin{displaymath}
   s[i] = \left\{
     \begin{array}{cl}
       t_1[i] & \text{if~ } t_1[i] = t_2[i]) = \ldots = t_k[i] \\
       - & \text{if~ } \text{otherwise} 
     \end{array}
   \right.
\end{displaymath} 

Thus, our schema will only have specified values where every individual in $T$ has the same value at that same position. If our best performing individuals all have the same values at various alleles, this may hint that these assignments are correlated with success. Thus, it would be reasonable to search the neighborhood of this partial solution more thoroughly. 
\begin{figure}[h!]
\centering 
\begin{align*}
\text{Elite Individual 1} &: 0~1~0~0~1~0~1~1~0 			\\
\text{Elite Individual 2} &: 0~1~0~0~0~0~1~0~0 			\\
\text{Elite Individual 3} &: 1~1~0~1~1~0~1~1~0 			\\
\text{Resultant Genetic Overlay} &:   -1~0--0~1-0			\\
\text{Unmodified New Individual} &: 1~0~0~1~1~0~1~1~1	\\		
\text{Resultant Individual} &: 1~1~0~1~1~0~1~1~0
\end{align*}
\caption{Production and Application of an Elitist Schema Overlay}
\label{ESO-Fig}
\end{figure}

Figure-\ref{ESO-Fig} demonstrates how elitist schema overlays are constructed and the result of its application. It should be noted that our $c$ can be created using any existing, or future, genetic operator. This was done intentionally to explore its behavior in several scenarios. This process allows us to search around those genes that are common among the fittest members in our population. 

Admittedly, the effects of this method will depend greatly upon our choice of $k$. For instance, the choice $k = 1$ will replace every individual that has a genetic overlay applied with the highest ranked member of the population. This is problematic, since it will instantly lead us to convergence. Likewise, a large value of $k$, will greatly reduce the probability that $t_1[i] = t_2[i] = \ldots = t_k[i]$ is true. This would lead us to checking a large number of alleles and, in the likeliest case, doing little to nothing with that information.

To determine reasonable values for $k$, it is helpful to know what the probability of an allele being specified in an elitist schema overlay is. We will denote $\alpha_i$ to be this probability, and $x_i$ to represent the size of the domain of the $i$th allele for a genetic sequence of length $n$. Note that this assumes that each value for an allele has an equal probability of showing up in a selected genetic sequence at allele $i$. If this is not the case, then this gives us a lower bound of the probability that this property is true.

\[ \alpha_i = P(\text{\emph{k} parents matching \emph{i}th allele}) = \left(\frac{1}{x_i}\right)^{k-1} \]

With this, we can easily derive the probabilities of having no matches and a total match for a chromosome of length $n$ in terms of $\alpha_i$.

\begin{align*}
P( \text{No matches})&= \prod\limits_{i = 1}^n (1 - \alpha_i) \\
P( \text{All matches})&= \prod\limits_{i = 1}^n (\alpha_i)
\end{align*}

Thus, our choice of $k$ should be made carefully, but there are a large number of possibilities that we could easily consider. A fixed and predetermined $k$ could be chosen, $k$ could be randomized for each generation, or $k$ could be set to the number of individuals above a certain fitness threshold; however, the successes of Memetic Algorithms inspired a different approach. If we create an inverse relationship between the generations elapsed and our choice of $k$ we get some interesting properties:

\begin{enumerate}

\item Narrowing Search - Since the initial $k$ values will be very large, it is unlikely that $t_1(i) = t_2(i) = \ldots = t_k(i)$, and so we will not disturb the initial natural diversity with the operator.  Likewise, as our $k$ drops our genetic overlay has a higher chance to be mostly specified, thus we will be searching the narrowing neighborhood of the best performing solutions discovered so far \cite{Neri11}.

\item Bounded Convergence - We can control how quickly $k$ decreases, and by this, how quickly our population will converge towards the best known solutions. When we set $k=1$ we will instantly converge the entire target population of this operator, and so the minimum convergence rate can now be set by the user.

\end{enumerate}

%
% GA Theory
%
% Holland Quote - pg. 66
% Goldberg Information - pg. 41
%
A close relationship can be seen between these operators, the schema theorem, and the building-block hypothesis\cite{Goldberg89, Holland75}. The schema theorem, in Holland's own words, states, "The adaptive system must, as an integral part of its search of $a$, persistently test and incorporate structural properties associated with better performance \cite{Holland75}." Thus, by identifying the alleles associated with high performance, we can use a genetic overlay to incorporate them into our entire population. This will lead to the schemata being tested by the fitness function more often since it is present in more individuals. The building block hypothesis states that the juxtaposition of building blocks, or schemata that are have high fitness values and low defining lengths, are integral to the successes of Genetic Algorithms \cite{Goldberg89}. Therefore, we should be careful to build genetic overlays that are correlated to high fitness values while leaving ample room to search within.

Strangely, when Forrest and Mitchell tested the performance of Genetic Algorithms against Hill-Climbing Algorithms on the Royal Road function, whose definition is tightly coupled with the building-block hypothesis, Genetic Algorithms were out-performed\cite{Forrest93} by Random Hill-Climbing Algorithms. Results like this have lead to criticism of the strength of the underlying assumptions and the narrowness over which the schema theorem and building-block hypothesis could be applied\cite{Burjorjee08, Senaratna05}. This has lead to the use of effective fitness measures and coarser graining on the size of building-block schemata to describe the evolutions of schemata over time\cite{Stephens99}.

The underlying mechanics of successful Genetic Algorithms are still being debated, but the exploitation of current, successful genetic sequences is still fundamental to the field as a whole\cite{Russell10, Senaratna05}. Genetic overlays were designed to speed up the propagation of schemata in a population, and elitist schema overlays search the fittest individuals for useful schemata to propogate. To make comparative statements about the effectiveness of elitist schema overlays, we also implemented successful genetic operators from the literature.